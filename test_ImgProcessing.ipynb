{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "test-ImgProcessing.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9uF3sZ2Qex1"
      },
      "source": [
        "#Surgical Image Enhancement , De-smoking and segmentation ofsurgical tools"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kVo4Y3AQlCn"
      },
      "source": [
        "#Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GAATCViaQdet"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "from mrcnn.config import Config\n",
        "from mrcnn import utils\n",
        "import mrcnn.model as modellib\n",
        "from mrcnn import visualize\n",
        "from scipy.spatial import distance\n",
        "import smoky as ex"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75MRTqluSU_x"
      },
      "source": [
        "#Image Enhancement using Constrast Ltd Adaptive Histogram Equalization (CLAHE)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKz5fFLjQoQh"
      },
      "source": [
        "def hisEqulColor(img):\n",
        "  ycrcb = cv2.cvtColor(img, cv2.COLOR_BGR2YCR_CB)\n",
        "  channels = cv2.split(ycrcb)\n",
        "  clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
        "  channels[0] = clahe.apply(channels[0])\n",
        "  cv2.merge(channels, ycrcb)\n",
        "  cv2.cvtColor(ycrcb, cv2.COLOR_YCR_CB2BGR, img)\n",
        "  return img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ub_McjOzUtQk"
      },
      "source": [
        "#Create classes for Image Segmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_DKZabzLQoNB"
      },
      "source": [
        "#testing- for debugging: whether masks loaded properly\n",
        "def get_ax(rows=1, cols=1, size=8):\n",
        "  _, ax = plt.subplots(rows, cols, figsize=(size * cols, size * rows))\n",
        "  return ax\n",
        "\n",
        "#class to control h/w- for segmentation\n",
        "class MicrocontrollerConfig(Config):\n",
        "  # Give the configuration a recognizable name\n",
        "  NAME = \"microcontroller_segmentation\"\n",
        "  NUM_CLASSES = 1 + 1\n",
        "  GPU_COUNT = 1\n",
        "  IMAGES_PER_GPU = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wFbam_AqQoIh"
      },
      "source": [
        "class MicrocontrollerDataset(utils.Dataset):\n",
        "  #load dataset of medical images\n",
        "  def load_dataset(self, dataset_dir):\n",
        "    self.add_class('dataset', 1, 'instrument')\n",
        "\n",
        "    #create json corresponding to png files to apply mask-RCNN\n",
        "    #organize dataset and corr images for mask\n",
        "    # find all images\n",
        "    for i, filename in enumerate(os.listdir(dataset_dir)):\n",
        "      if '.png' in filename:\n",
        "        self.add_image('dataset', image_id=i, path=os.path.join(dataset_dir, filename),\n",
        "                       annotation=os.path.join(dataset_dir, filename.replace('.png', '.json')))\n",
        "\n",
        "  #create and extract mask\n",
        "  def extract_masks(self, filename):\n",
        "    json_file = os.path.join(filename)\n",
        "    with open(json_file) as f:\n",
        "      img_anns = json.load(f)\n",
        "    masks = np.zeros([600, 800, len(img_anns['shapes'])], dtype='uint8')\n",
        "    classes = []\n",
        "    for i, anno in enumerate(img_anns['shapes']):\n",
        "      mask = np.zeros([600, 800], dtype=np.uint8)\n",
        "      cv2.fillPoly(mask, np.array([anno['points']], dtype=np.int32), 1)\n",
        "      masks[:, :, i] = mask\n",
        "      classes.append(self.class_names.index(anno['label']))\n",
        "    return masks, classes\n",
        "\n",
        "  # load the masks for an image\n",
        "  def load_mask(self, image_id):\n",
        "    # get details of image\n",
        "    info = self.image_info[image_id]\n",
        "    # define box file location\n",
        "    path = info['annotation']\n",
        "    # load XML\n",
        "    masks, classes = self.extract_masks(path)\n",
        "    return masks, np.asarray(classes, dtype='int32')\n",
        "\n",
        "  #handle images path\n",
        "  def image_reference(self, image_id):\n",
        "    info = self.image_info[image_id]\n",
        "    return info['path']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dsRPC-lnU9ry"
      },
      "source": [
        "#Find Inter-Instrument Distance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5rWDhLmlQ8Jq"
      },
      "source": [
        "#create class to handle h/w: to find distances\n",
        "class InferenceConfig(MicrocontrollerConfig):\n",
        "  GPU_COUNT = 1\n",
        "  IMAGES_PER_GPU = 1\n",
        "\n",
        "def midpoint(ptA, ptB):\n",
        "  return (np.round((ptA[0]+ptB[0]) * 0.5).astype(int), np.round((ptA[1]+ptB[1]) * 0.5).astype(int))\n",
        "  \n",
        "#\n",
        "def drawing(r, resized1):\n",
        "  bb = []\n",
        "  for i in r:\n",
        "    (mX, mY) = midpoint((i[1],i[0]), (i[3],i[2]))         #midpoint of bounding boxes\n",
        "    bb.append((mX, mY))\n",
        "\n",
        "  print(\"BB :-\", bb)\n",
        "  radius = 10                 #radius of circle\n",
        "  color = (0, 255, 0)\n",
        "  thickness = -1\n",
        "\n",
        "  #create points (circles for endpoints)\n",
        "  if len(bb) == 1:\n",
        "    cv2.circle(resized1, bb[0], radius, color, thickness)           #circles for lines midpoint\n",
        "    cv2.imshow(\"hello\", resized1)\n",
        "    cv2.waitKey(0)\n",
        "\n",
        "  for i in range(len(bb)):\n",
        "    if i == (len(bb) - 1):              #same lines midpoint shouldnt be calculated\n",
        "      continue\n",
        "    else:\n",
        "      dst = str(np.round(distance.euclidean(bb[i], bb[i+1])*0.0085)) + \" cm\" #1px= 0.0085cm = ratio(real/px_dist)\n",
        "      cv2.circle(resized1, bb[i], radius, color, thickness)\n",
        "      cv2.circle(resized1, bb[i+1], radius, color, thickness)\n",
        "      cv2.line(resized1, bb[i], bb[i+1], color, thickness=3) #generate line b/w points\n",
        "      (x, y) = midpoint(bb[i], bb[i+1])\n",
        "      cv2.putText(resized1, dst, (x, y), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 3, cv2.LINE_AA) #display dist b/w points\n",
        "  return resized1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1vIwzJfRMSs"
      },
      "source": [
        "# Root directory of the project\n",
        "ROOT_DIR = os.path.abspath(\"/home/sayak/Documents/personal/vit/study/thirdY6thSem/tarp/surgical_tool_seg\")\n",
        "\n",
        "# Import Mask RCNN\n",
        "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
        "\n",
        "# Directory to save logs and trained model\n",
        "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
        "\n",
        "# # Local path to trained weights file\n",
        "# COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
        "# # Download COCO trained weights from Releases if needed\n",
        "# if not os.path.exists(COCO_MODEL_PATH):\n",
        "#     utils.download_trained_weights(COCO_MODEL_PATH)\n",
        "config = MicrocontrollerConfig()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZMGLuQPlTTl"
      },
      "source": [
        "#Split into Training and Testing/ Validation Datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "krcKb-vwRMQo"
      },
      "source": [
        "# Create training and validation set\n",
        "# train set\n",
        "dataset_train = MicrocontrollerDataset()\n",
        "dataset_train.load_dataset('Mask_RCNN/seggy/train')\n",
        "dataset_train.prepare()\n",
        "print('Train: %d' % len(dataset_train.image_ids))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FOTabNHORMOm"
      },
      "source": [
        "# test/val set\n",
        "dataset_val = MicrocontrollerDataset()\n",
        "dataset_val.load_dataset('Mask_RCNN/seggy/test')\n",
        "dataset_val.prepare()\n",
        "print('Test: %d' % len(dataset_val.image_ids))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNk7z1NORMNM"
      },
      "source": [
        "inference_config = InferenceConfig()\n",
        "\n",
        "# Recreate the model in inference mode\n",
        "model = modellib.MaskRCNN(mode=\"inference\", config=inference_config, model_dir=MODEL_DIR)\n",
        "\n",
        "# model_path = model.find_last()\n",
        "model_path = \"/home/sayak/Documents/personal/vit/study/thirdY6thSem/tarp/surgical_tool_seg/Mask_RCNN/logs/microcontroller_segmentation20201130T1644/mask_rcnn_microcontroller_segmentation_0001.h5\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjRWyF--RMK1"
      },
      "source": [
        "# Load trained weights\n",
        "print(\"Loading weights from \", model_path)\n",
        "model.load_weights(model_path, by_name=True)\n",
        "\n",
        "# x = cv2.imread(\"/opt/lampp/htdocs/Hackathon/i1.png\")\n",
        "x = cv2.imread(\"/home/sayak/Documents/personal/vit/study/thirdY6thSem/tarp/surgical_tool_seg/Mask_RCNN/seggy/test/img_51_raw.png\")\n",
        "# x = cv2.imread(\"/opt/lampp/htdocs/Hackathon/Mask_RCNN/seggy/test/img_116_raw.png\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3sGKemXudmlj"
      },
      "source": [
        "#De-Smoking and Enhancement"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHe4X3pXRMH_"
      },
      "source": [
        "original_image = cv2.cvtColor(x, cv2.COLOR_RGB2BGR)\n",
        "img2 = hisEqulColor(original_image)\n",
        "resized = cv2.resize(img2, (1280,1216), interpolation=cv2.INTER_AREA)\n",
        "resized1 = cv2.cvtColor(resized, cv2.COLOR_BGR2RGB)\n",
        "results = model.detect([resized], verbose=1)\n",
        "r = results[0]\n",
        "de = ex.dehaze(resized1)\n",
        "de = hisEqulColor(de)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ciWVrBDUMXJ"
      },
      "source": [
        "#Run the Image Enhancement and Segmentation Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4cW1Z7g5RMFS"
      },
      "source": [
        "def main(option):\n",
        "  if option == 0:\n",
        "    visualize.display_instances(resized, r['rois'], r['masks'], r['class_ids'], \n",
        "                                dataset_val.class_names, figsize=(8, 8))\n",
        "\n",
        "  elif option == 1:\n",
        "    z = drawing(r['rois'], resized1)\n",
        "    z = cv2.resize(z, (800,800))\n",
        "    cv2.imshow(\"hello\", z)\n",
        "    cv2.waitKey(0)\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "  elif option == 2:\n",
        "    de1 = cv2.resize(de, (800,800), interpolation=cv2.INTER_AREA)\n",
        "    cv2.imshow(\"hello\", de1)\n",
        "    cv2.waitKey(0)\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "  elif option == 3:\n",
        "    de2 = cv2.resize(de, (1280,1216), interpolation=cv2.INTER_AREA)\n",
        "    de2 = cv2.cvtColor(de2, cv2.COLOR_RGB2BGR)\n",
        "    res = model.detect([de2], verbose=1)                #runs maskrcnn\n",
        "    rf = res[0]\n",
        "    de3 = cv2.cvtColor(de2, cv2.COLOR_BGR2RGB)\n",
        "    z = drawing(rf['rois'], de3)    #rois = region of interest...finding coord(bounding box). de3=img on which circles/lines drawn\n",
        "    z = cv2.resize(z, (800,800))\n",
        "    cv2.imshow(\"hello\", z)\n",
        "    cv2.waitKey(0)\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "  elif option == 4:\n",
        "    de2 = cv2.resize(de, (1280,1216), interpolation=cv2.INTER_AREA)\n",
        "    de2 = cv2.cvtColor(de2, cv2.COLOR_RGB2BGR)\n",
        "    res = model.detect([de2], verbose=1)\n",
        "    rf = res[0]\n",
        "    visualize.display_instances(de2, rf['rois'], rf['masks'], rf['class_ids'], \n",
        "                                dataset_val.class_names, figsize=(8, 8))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "buADbz3XQ8GR"
      },
      "source": [
        "print(\"Choice details: \\n\"+\n",
        "      \"0 = Segmented image\\n\"+\n",
        "      \"1 = Enhanced and distance image\\n\"+\n",
        "      \"2 = De-Smoking\\n\"+\n",
        "      \"3 = De-Smoking and Distance\\n\"+\n",
        "      \"4 = De-Smoking and segmentation\\n\")\n",
        "num_ip = int(input(\"enter choice to run the model(0/1/2/3/4): \"))\n",
        "main(num_ip)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}